{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ec0567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 253 files belonging to 2 classes.\n",
      "Found 400 files belonging to 2 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define constants\n",
    "batch_size = 100\n",
    "img_height = 250\n",
    "img_width = 250\n",
    "\n",
    "# Load training and testing datasets\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    r'C:\\Users\\admin\\Desktop\\AI\\Brain_Tumar\\train',\n",
    "    seed=101,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    r'C:\\Users\\admin\\Desktop\\AI\\Brain_tumor_images',\n",
    "    seed=101,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Get class names\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "# Prefetch and cache datasets\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Define the ANN model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(img_height, img_width, 3)),  \n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(70, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_history = model.fit(train_ds,\n",
    "                          validation_data=test_ds,\n",
    "                          epochs=50)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results = model.evaluate(test_ds)\n",
    "\n",
    "# Plot model architecture\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(model_history.history['loss'], label='Training Loss')\n",
    "plt.plot(model_history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(30, 30))\n",
    "plt.plot(model_history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(model_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(25, 35))\n",
    "for images, labels in test_ds.take(1):\n",
    "    predictions = model.predict(images)\n",
    "    for i in range(40):\n",
    "        ax = plt.subplot(10, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        predicted_label = class_names[np.argmax(predictions[i])]\n",
    "        actual_label = class_names[labels[i]]\n",
    "        color = \"green\" if predicted_label == actual_label else \"red\"\n",
    "        plt.title(f\"Predicted: {predicted_label}\\nActual: {actual_label}\", color=color)\n",
    "        plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a68471d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 187500)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               96000512  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 70)                7070      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                3550      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                1020      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96063662 (366.45 MB)\n",
      "Trainable params: 96063662 (366.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d57ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e884b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
