{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c6ea4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Matrix (R):\n",
      "[[0.         0.32248541 0.38229846 0.50100736 0.42599816 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.31601962 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.43289757 0.         0.61764281 0.67160811 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.59594642 0.41412581 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.75037021 0.         0.25158155 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.67572464\n",
      "  0.         0.         0.        ]\n",
      " [0.64418023 0.11534808 0.         0.         0.61481074 0.2362195\n",
      "  0.55122059 0.62918909 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.37026574 0.         0.         0.69572719 0.         0.\n",
      "  0.         0.44057878 0.         0.         0.         0.27031579\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.30707614 0.         0.\n",
      "  0.         0.49924328 0.54762037 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.30804016 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.4464421  0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.27659549 0.30087699 0.42483845\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.44608706 0.\n",
      "  0.         0.         0.         0.06400726 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.39048816\n",
      "  0.         0.         0.         0.45114341 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.27948855\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.56766699 0.         0.36957754 0.\n",
      "  0.49269169 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.33887852 0.         0.\n",
      "  0.         0.33691302 0.         0.         0.         0.60730792\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.28269812 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.38369166 0.56664778 0.         0.\n",
      "  0.31296321 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.69743697 0.         0.\n",
      "  0.         0.         0.34985332 0.         0.         0.54756694\n",
      "  0.         0.44352535 0.         0.         0.         0.\n",
      "  0.         0.         0.53531013]\n",
      " [0.         0.         0.28263141 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.2330662  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.29775419\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32289374\n",
      "  0.54788168 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.64886066 0.         0.40673982 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.24246532\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.48053171 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.33689523 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.54994457 0.         0.46518205 0.\n",
      "  0.42651082 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.2723778\n",
      "  0.         0.         0.         0.         0.54494299 0.\n",
      "  0.         0.41425525 0.         0.58326877 0.         0.\n",
      "  0.         0.56262678 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.39150651 0.         0.         0.         0.         0.\n",
      "  0.40834929 0.         0.49157781 0.         0.50099503 0.\n",
      "  0.47904874 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.3185121  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.57592151 0.         0.46218068 0.         0.\n",
      "  0.43460686 0.         0.52059276]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13813608 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.22365464 0.         0.43440215 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.44167965 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.50619785 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.78997695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.29078488]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.15460362 0.28951751 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14110639 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.59917477 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.29028727 0.         0.         0.19888411\n",
      "  0.         0.         0.        ]]\n",
      "\n",
      "Learned Q-values:\n",
      "[[0.         5.20721261 5.19213031 5.63413983 5.13926882 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         5.14729183 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [5.15211715 5.06696262 5.58672512 5.62995847 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [5.66667227 5.48108843 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         5.34425761 0.         5.08285377 0.         0.\n",
      "  0.         0.         0.         0.         0.         5.55272191\n",
      "  0.         0.         0.        ]\n",
      " [5.26952217 5.00007528 0.         0.         5.70348053 4.95091588\n",
      "  4.26095616 5.14643799 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [5.08948532 0.         0.         5.82885966 5.24597369 0.\n",
      "  0.         0.         0.         0.         0.         5.12844378\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         5.44020862 0.         0.\n",
      "  0.         5.36799845 5.23855153 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         5.44117264 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         5.40682062 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         5.40972796 5.01414765 4.74954437\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         4.94002519 0.\n",
      "  0.         0.         0.         4.5788375  0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         5.10518453\n",
      "  0.         0.         0.         5.21214573 0.         0.\n",
      "  0.         0.         0.         0.         0.         5.11502992\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         5.25859815 0.         5.26814189 0.\n",
      "  5.46631584 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         5.09988084 0.         0.\n",
      "  0.         4.96582191 0.         0.         0.         5.44284928\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         5.3713679  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         5.32846681 5.39791999 0.         0.\n",
      "  5.20767744 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         5.4584393  0.         0.\n",
      "  0.         0.         5.29462847 0.         0.         5.3831083\n",
      "  0.         5.24756285 0.         0.         0.         0.\n",
      "  0.         0.         5.52624905]\n",
      " [0.         0.         5.09246327 0.         0.         0.\n",
      "  0.         0.         0.         0.         5.13163056 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         5.14323211\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         5.15712485\n",
      "  5.52150583 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [5.36808024 0.         5.21657167 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         5.10059331\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         4.99778061 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  5.23160947 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         5.24087572 0.         5.3637464  0.\n",
      "  5.40013496 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         5.13050579\n",
      "  0.         0.         0.         0.         5.25339152 0.\n",
      "  0.         5.21829274 0.         5.43857138 0.         0.\n",
      "  0.         5.09486534 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  5.33781944 0.         0.         0.         0.         0.\n",
      "  4.9966384  0.         5.45195632 0.         5.00816621 0.\n",
      "  5.20395517 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  4.3965434  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         4.95962275 0.         5.31748328 0.         0.\n",
      "  5.15951328 0.         5.51153169]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         5.00689125 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  5.11836888 0.         5.39478067 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         5.34844034 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         5.3160297  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         5.41888585 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         5.28172381]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         4.95864111 5.24989603 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  5.03582063 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  5.54548769 0.         0.         0.         0.         0.\n",
      "  0.         0.         5.25066578 0.         0.         5.04436202\n",
      "  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "adj_list = {\n",
    "    0: [1, 2, 3, 4, 15],\n",
    "    1: [0, 1, 2, 3],\n",
    "    2: [0, 15, 13, 23, 1],\n",
    "    3: [0, 1, 4, 5, 6, 7],\n",
    "    4: [0, 3, 4, 11],\n",
    "    5: [3, 7, 8],\n",
    "    6: [3, 20],\n",
    "    7: [3, 4, 5, 16, 21],\n",
    "    8: [9, 5, 17],\n",
    "    9: [8, 12, 10],\n",
    "    10: [13, 9, 17],\n",
    "    11: [4, 14, 15, 18],\n",
    "    12: [9, 14, 19, 17, 26],\n",
    "    13: [2, 23, 10],\n",
    "    14: [11, 12],\n",
    "    15: [0, 2, 11],\n",
    "    16: [7, 18],\n",
    "    17: [10, 8, 12],\n",
    "    18: [11, 16, 19, 25, 21],\n",
    "    19: [12, 18, 20, 24, 22],\n",
    "    20: [6, 21, 19, 24, 26],\n",
    "    21: [7, 18, 20],\n",
    "    22: [19],\n",
    "    23: [2, 13, 26],\n",
    "    24: [19, 20],\n",
    "    25: [18],\n",
    "    26: [12, 20, 23]\n",
    "}\n",
    "\n",
    "# Information: Node To Node From TenPercetD_W\n",
    "information = {\n",
    "    (0, 1): 0.3224854143,\n",
    "    (0, 2): 0.3822984557,\n",
    "    (0, 3): 0.5010073577,\n",
    "    (0, 4): 0.425998157,\n",
    "    (0, 15): 0.3160196195,\n",
    "    (1, 0): 0.4328975718,\n",
    "    (1, 2): 0.6176428141,\n",
    "    (1, 3): 0.6716081135,\n",
    "    (2, 0): 0.5959464208,\n",
    "    (2, 1): 0.4141258138,\n",
    "    (2, 13): 0.7503702102,\n",
    "    (2, 15): 0.2515815536,\n",
    "    (2, 23): 0.6757246435,\n",
    "    (3, 0): 0.6441802307,\n",
    "    (3, 1): 0.1153480802,\n",
    "    (3, 4): 0.614810743,\n",
    "    (3, 5): 0.2362195029,\n",
    "    (3, 6): 0.5512205929,\n",
    "    (3, 7): 0.6291890911,\n",
    "    (4, 0): 0.3702657392,\n",
    "    (4, 3): 0.6957271861,\n",
    "    (4, 7): 0.4405787781,\n",
    "    (4, 11): 0.2703157886,\n",
    "    (5, 3): 0.3070761406,\n",
    "    (5, 7): 0.4992432842,\n",
    "    (5, 8): 0.5476203713,\n",
    "    (6, 3): 0.3080401627,\n",
    "    (6, 20): 0.4464421034,\n",
    "    (7, 3): 0.2765954887,\n",
    "    (7, 4): 0.3008769896,\n",
    "    (7, 5): 0.4248384488,\n",
    "    (7, 16): 0.446087055,\n",
    "    (7, 21): 0.06400726476,\n",
    "    (8, 5): 0.3904881582,\n",
    "    (8, 9): 0.4511434057,\n",
    "    (8, 17): 0.2794885521,\n",
    "    (9, 8): 0.5676669918,\n",
    "    (9, 10): 0.369577537,\n",
    "    (9, 12): 0.4926916878,\n",
    "    (10, 9): 0.3388785174,\n",
    "    (10, 13): 0.3369130153,\n",
    "    (10, 17): 0.6073079151,\n",
    "    (11, 4): 0.2826981204,\n",
    "    (11, 14): 0.3836916617,\n",
    "    (11, 15): 0.5666477776,\n",
    "    (11, 18): 0.3129632055,\n",
    "    (12, 9): 0.6974369733,\n",
    "    (12, 14): 0.34985332,\n",
    "    (12, 17): 0.5475669363,\n",
    "    (12, 19): 0.4435253526,\n",
    "    (12, 26): 0.5353101287,\n",
    "    (13, 2): 0.282631413,\n",
    "    (13, 10): 0.2330662032,\n",
    "    (13, 23): 0.2977541939,\n",
    "    (14, 11): 0.3228937374,\n",
    "    (14, 12): 0.5478816812,\n",
    "    (15, 0): 0.6488606563,\n",
    "    (15, 2): 0.4067398184,\n",
    "    (15, 11): 0.2424653154,\n",
    "    (16, 7): 0.4805317103,\n",
    "    (16, 18): 0.3368952343,\n",
    "    (17, 8): 0.5499445657,\n",
    "    (17, 10): 0.4651820486,\n",
    "    (17, 12): 0.4265108166,\n",
    "    (18, 11): 0.272377799,\n",
    "    (18, 16): 0.5449429935,\n",
    "    (18, 19): 0.4142552459,\n",
    "    (18, 21): 0.5832687723,\n",
    "    (18, 25): 0.5626267756,\n",
    "    (19, 12): 0.3915065111,\n",
    "    (19, 18): 0.4083492938,\n",
    "    (19, 20): 0.491577807,\n",
    "    (19, 22): 0.5009950314,\n",
    "    (19, 24): 0.479048743,\n",
    "    (20, 6): 0.3185120973,\n",
    "    (20, 19): 0.5759215123,\n",
    "    (20, 21): 0.4621806759,\n",
    "    (20, 24): 0.4346068608,\n",
    "    (20, 26): 0.5205927609,\n",
    "    (21, 7): 0.1381360828,\n",
    "    (21, 18): 0.2236546413,\n",
    "    (21, 20): 0.4344021531,\n",
    "    (22, 19): 0.4416796452,\n",
    "    (23, 2): 0.5061978469,\n",
    "    (23, 13): 0.7899769485,\n",
    "    (23, 26): 0.2907848836,\n",
    "    (24, 19): 0.1546036158,\n",
    "    (24, 20): 0.2895175086,\n",
    "    (25, 18): 0.1411063944,\n",
    "    (26, 12): 0.5991747676,\n",
    "    (26, 20): 0.2902872652,\n",
    "    (26, 23): 0.198884108\n",
    "}\n",
    "\n",
    "# Function to calculate the reward for a given state and action\n",
    "def calculate_reward(state, action):\n",
    "    if (state, action) in information:\n",
    "        return information[(state, action)]\n",
    "    else:\n",
    "        return 0  # Default reward for invalid action\n",
    "\n",
    "# Convert adjacency list to matrix\n",
    "def adjacency_list_to_matrix(adj_list):\n",
    "    num_nodes = len(adj_list)\n",
    "    matrix = np.zeros((num_nodes, num_nodes))\n",
    "    for node, neighbors in adj_list.items():\n",
    "        for neighbor in neighbors:\n",
    "            matrix[node, neighbor] = 1\n",
    "    return matrix\n",
    "\n",
    "# Convert information dictionary to matrix\n",
    "def information_to_matrix(information, num_nodes):\n",
    "    R = np.zeros((num_nodes, num_nodes))\n",
    "    for (from_node, to_node), reward in information.items():\n",
    "        R[from_node, to_node] = reward\n",
    "    return R\n",
    "\n",
    "# Q-learning parameters\n",
    "gamma = 0.9  # Discount factor\n",
    "\n",
    "# Convert adjacency list to matrix\n",
    "num_nodes = len(adj_list)\n",
    "adj_matrix = adjacency_list_to_matrix(adj_list)\n",
    "\n",
    "# Convert information dictionary to matrix\n",
    "R = information_to_matrix(information, num_nodes)\n",
    "\n",
    "# Initialize Q-matrix\n",
    "Q = np.zeros_like(R)\n",
    "\n",
    "# Q-learning algorithm\n",
    "def q_learning(R, Q, num_episodes):\n",
    "    for _ in range(num_episodes):\n",
    "        state = np.random.randint(num_nodes)  # Random initial state\n",
    "        while True:\n",
    "            possible_actions = np.where(adj_matrix[state] == 1)[0]  # Get possible actions\n",
    "            action = np.random.choice(possible_actions)  # Choose action randomly\n",
    "            next_state = action  # Transition to next state\n",
    "            max_next_Q = np.max(Q[next_state])  # Find maximum Q-value for next state\n",
    "            Q[state, action] = R[state, action] + gamma * max_next_Q  # Update Q-value\n",
    "            state = next_state  # Update state\n",
    "            if state == state:  # Check if episode terminates\n",
    "                break\n",
    "\n",
    "# Example usage\n",
    "num_episodes = 1000\n",
    "q_learning(R, Q, num_episodes)\n",
    "\n",
    "# Print the reward matrix (R)\n",
    "print(\"Reward Matrix (R):\")\n",
    "print(R)\n",
    "\n",
    "# Print the learned Q-values\n",
    "print(\"\\nLearned Q-values:\")\n",
    "print(Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c279d556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66046bee",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 192\u001b[0m\n\u001b[0;32m    189\u001b[0m q_learning(R, Q, num_episodes)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Find shortest path\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m shortest_path \u001b[38;5;241m=\u001b[39m q_learning_shortest_path(Q, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m26\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShortest path:\u001b[39m\u001b[38;5;124m\"\u001b[39m, shortest_path)\n",
      "Cell \u001b[1;32mIn[2], line 184\u001b[0m, in \u001b[0;36mq_learning_shortest_path\u001b[1;34m(Q, start, goal)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m start \u001b[38;5;241m!=\u001b[39m goal:\n\u001b[0;32m    183\u001b[0m     next_step \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(Q[start])\n\u001b[1;32m--> 184\u001b[0m     path\u001b[38;5;241m.\u001b[39mappend(next_step)\n\u001b[0;32m    185\u001b[0m     start \u001b[38;5;241m=\u001b[39m next_step\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "adj_list = {\n",
    "    0: [1, 2, 3, 4, 15],\n",
    "    1: [0, 1, 2, 3],\n",
    "    2: [0, 15, 13, 23, 1],\n",
    "    3: [0, 1, 4, 5, 6, 7],\n",
    "    4: [0, 3, 4, 11],\n",
    "    5: [3, 7, 8],\n",
    "    6: [3, 20],\n",
    "    7: [3, 4, 5, 16, 21],\n",
    "    8: [9, 5, 17],\n",
    "    9: [8, 12, 10],\n",
    "    10: [13, 9, 17],\n",
    "    11: [4, 14, 15, 18],\n",
    "    12: [9, 14, 19, 17, 26],\n",
    "    13: [2, 23, 10],\n",
    "    14: [11, 12],\n",
    "    15: [0, 2, 11],\n",
    "    16: [7, 18],\n",
    "    17: [10, 8, 12],\n",
    "    18: [11, 16, 19, 25, 21],\n",
    "    19: [12, 18, 20, 24, 22],\n",
    "    20: [6, 21, 19, 24, 26],\n",
    "    21: [7, 18, 20],\n",
    "    22: [19],\n",
    "    23: [2, 13, 26],\n",
    "    24: [19, 20],\n",
    "    25: [18],\n",
    "    26: [12, 20, 23]\n",
    "}\n",
    "\n",
    "# Information: Node To Node From TenPercetD_W\n",
    "information = {\n",
    "    (0, 1): 0.3224854143,\n",
    "    (0, 2): 0.3822984557,\n",
    "    (0, 3): 0.5010073577,\n",
    "    (0, 4): 0.425998157,\n",
    "    (0, 15): 0.3160196195,\n",
    "    (1, 0): 0.4328975718,\n",
    "    (1, 2): 0.6176428141,\n",
    "    (1, 3): 0.6716081135,\n",
    "    (2, 0): 0.5959464208,\n",
    "    (2, 1): 0.4141258138,\n",
    "    (2, 13): 0.7503702102,\n",
    "    (2, 15): 0.2515815536,\n",
    "    (2, 23): 0.6757246435,\n",
    "    (3, 0): 0.6441802307,\n",
    "    (3, 1): 0.1153480802,\n",
    "    (3, 4): 0.614810743,\n",
    "    (3, 5): 0.2362195029,\n",
    "    (3, 6): 0.5512205929,\n",
    "    (3, 7): 0.6291890911,\n",
    "    (4, 0): 0.3702657392,\n",
    "    (4, 3): 0.6957271861,\n",
    "    (4, 7): 0.4405787781,\n",
    "    (4, 11): 0.2703157886,\n",
    "    (5, 3): 0.3070761406,\n",
    "    (5, 7): 0.4992432842,\n",
    "    (5, 8): 0.5476203713,\n",
    "    (6, 3): 0.3080401627,\n",
    "    (6, 20): 0.4464421034,\n",
    "    (7, 3): 0.2765954887,\n",
    "    (7, 4): 0.3008769896,\n",
    "    (7, 5): 0.4248384488,\n",
    "    (7, 16): 0.446087055,\n",
    "    (7, 21): 0.06400726476,\n",
    "    (8, 5): 0.3904881582,\n",
    "    (8, 9): 0.4511434057,\n",
    "    (8, 17): 0.2794885521,\n",
    "    (9, 8): 0.5676669918,\n",
    "    (9, 10): 0.369577537,\n",
    "    (9, 12): 0.4926916878,\n",
    "    (10, 9): 0.3388785174,\n",
    "    (10, 13): 0.3369130153,\n",
    "    (10, 17): 0.6073079151,\n",
    "    (11, 4): 0.2826981204,\n",
    "    (11, 14): 0.3836916617,\n",
    "    (11, 15): 0.5666477776,\n",
    "    (11, 18): 0.3129632055,\n",
    "    (12, 9): 0.6974369733,\n",
    "    (12, 14): 0.34985332,\n",
    "    (12, 17): 0.5475669363,\n",
    "    (12, 19): 0.4435253526,\n",
    "    (12, 26): 0.5353101287,\n",
    "    (13, 2): 0.282631413,\n",
    "    (13, 10): 0.2330662032,\n",
    "    (13, 23): 0.2977541939,\n",
    "    (14, 11): 0.3228937374,\n",
    "    (14, 12): 0.5478816812,\n",
    "    (15, 0): 0.6488606563,\n",
    "    (15, 2): 0.4067398184,\n",
    "    (15, 11): 0.2424653154,\n",
    "    (16, 7): 0.4805317103,\n",
    "    (16, 18): 0.3368952343,\n",
    "    (17, 8): 0.5499445657,\n",
    "    (17, 10): 0.4651820486,\n",
    "    (17, 12): 0.4265108166,\n",
    "    (18, 11): 0.272377799,\n",
    "    (18, 16): 0.5449429935,\n",
    "    (18, 19): 0.4142552459,\n",
    "    (18, 21): 0.5832687723,\n",
    "    (18, 25): 0.5626267756,\n",
    "    (19, 12): 0.3915065111,\n",
    "    (19, 18): 0.4083492938,\n",
    "    (19, 20): 0.491577807,\n",
    "    (19, 22): 0.5009950314,\n",
    "    (19, 24): 0.479048743,\n",
    "    (20, 6): 0.3185120973,\n",
    "    (20, 19): 0.5759215123,\n",
    "    (20, 21): 0.4621806759,\n",
    "    (20, 24): 0.4346068608,\n",
    "    (20, 26): 0.5205927609,\n",
    "    (21, 7): 0.1381360828,\n",
    "    (21, 18): 0.2236546413,\n",
    "    (21, 20): 0.4344021531,\n",
    "    (22, 19): 0.4416796452,\n",
    "    (23, 2): 0.5061978469,\n",
    "    (23, 13): 0.7899769485,\n",
    "    (23, 26): 0.2907848836,\n",
    "    (24, 19): 0.1546036158,\n",
    "    (24, 20): 0.2895175086,\n",
    "    (25, 18): 0.1411063944,\n",
    "    (26, 12): 0.5991747676,\n",
    "    (26, 20): 0.2902872652,\n",
    "    (26, 23): 0.198884108\n",
    "}\n",
    "# Function to calculate the reward for a given state and action\n",
    "def calculate_reward(state, action):\n",
    "    if (state, action) in information:\n",
    "        return information[(state, action)]\n",
    "    else:\n",
    "        return 0  # Default reward for invalid action\n",
    "\n",
    "# Convert adjacency list to matrix\n",
    "def adjacency_list_to_matrix(adj_list):\n",
    "    num_nodes = len(adj_list)\n",
    "    matrix = np.zeros((num_nodes, num_nodes))\n",
    "    for node, neighbors in adj_list.items():\n",
    "        for neighbor in neighbors:\n",
    "            matrix[node, neighbor] = 1\n",
    "    return matrix\n",
    "\n",
    "# Convert information dictionary to matrix\n",
    "def information_to_matrix(information, num_nodes):\n",
    "    R = np.zeros((num_nodes, num_nodes))\n",
    "    for (from_node, to_node), reward in information.items():\n",
    "        R[from_node, to_node] = reward\n",
    "    return R\n",
    "\n",
    "# Q-learning parameters\n",
    "gamma = 0.9  # Discount factor\n",
    "num_episodes = 10\n",
    "\n",
    "# Convert adjacency list to matrix\n",
    "num_nodes = len(adj_list)\n",
    "adj_matrix = adjacency_list_to_matrix(adj_list)\n",
    "\n",
    "# Convert information dictionary to matrix\n",
    "R = information_to_matrix(information, num_nodes)\n",
    "\n",
    "# Initialize Q-matrix\n",
    "Q = np.zeros_like(R)\n",
    "\n",
    "# Q-learning algorithm\n",
    "def q_learning(R, Q, num_episodes):\n",
    "    for _ in range(num_episodes):\n",
    "        state = np.random.randint(num_nodes)  # Random initial state\n",
    "        while True:\n",
    "            possible_actions = np.where(adj_matrix[state] == 1)[0]  # Get possible actions\n",
    "            action = np.random.choice(possible_actions)  # Choose action randomly\n",
    "            next_state = action  # Transition to next state\n",
    "            max_next_Q = np.max(Q[next_state])  # Find maximum Q-value for next state\n",
    "            Q[state, action] = R[state, action] + gamma * max_next_Q  # Update Q-value\n",
    "            state = next_state  # Update state\n",
    "            if state == state:  # Check if episode terminates\n",
    "                break\n",
    "\n",
    "# Function to find the shortest path using learned Q-values\n",
    "def q_learning_shortest_path(Q, start, goal):\n",
    "    path = [start]\n",
    "    while start != goal:\n",
    "        next_step = np.argmax(Q[start])\n",
    "        path.append(next_step)\n",
    "        start = next_step\n",
    "    return path\n",
    "\n",
    "# Run Q-learning algorithm\n",
    "q_learning(R, Q, num_episodes)\n",
    "\n",
    "# Find shortest path\n",
    "shortest_path = q_learning_shortest_path(Q, 0, 26)\n",
    "print(\"Shortest path:\", shortest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c4c09f",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 190\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m    189\u001b[0m shortest_path_generator \u001b[38;5;241m=\u001b[39m q_learning_shortest_path(Q, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m26\u001b[39m)\n\u001b[1;32m--> 190\u001b[0m shortest_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(shortest_path_generator)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShortest path:\u001b[39m\u001b[38;5;124m\"\u001b[39m, shortest_path)\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "adj_list = {\n",
    "    0: [1, 2, 3, 4, 15],\n",
    "    1: [0, 1, 2, 3],\n",
    "    2: [0, 15, 13, 23, 1],\n",
    "    3: [0, 1, 4, 5, 6, 7],\n",
    "    4: [0, 3, 4, 11],\n",
    "    5: [3, 7, 8],\n",
    "    6: [3, 20],\n",
    "    7: [3, 4, 5, 16, 21],\n",
    "    8: [9, 5, 17],\n",
    "    9: [8, 12, 10],\n",
    "    10: [13, 9, 17],\n",
    "    11: [4, 14, 15, 18],\n",
    "    12: [9, 14, 19, 17, 26],\n",
    "    13: [2, 23, 10],\n",
    "    14: [11, 12],\n",
    "    15: [0, 2, 11],\n",
    "    16: [7, 18],\n",
    "    17: [10, 8, 12],\n",
    "    18: [11, 16, 19, 25, 21],\n",
    "    19: [12, 18, 20, 24, 22],\n",
    "    20: [6, 21, 19, 24, 26],\n",
    "    21: [7, 18, 20],\n",
    "    22: [19],\n",
    "    23: [2, 13, 26],\n",
    "    24: [19, 20],\n",
    "    25: [18],\n",
    "    26: [12, 20, 23]\n",
    "}\n",
    "\n",
    "# Information: Node To Node From TenPercetD_W\n",
    "information = {\n",
    "    (0, 1): 0.3224854143,\n",
    "    (0, 2): 0.3822984557,\n",
    "    (0, 3): 0.5010073577,\n",
    "    (0, 4): 0.425998157,\n",
    "    (0, 15): 0.3160196195,\n",
    "    (1, 0): 0.4328975718,\n",
    "    (1, 2): 0.6176428141,\n",
    "    (1, 3): 0.6716081135,\n",
    "    (2, 0): 0.5959464208,\n",
    "    (2, 1): 0.4141258138,\n",
    "    (2, 13): 0.7503702102,\n",
    "    (2, 15): 0.2515815536,\n",
    "    (2, 23): 0.6757246435,\n",
    "    (3, 0): 0.6441802307,\n",
    "    (3, 1): 0.1153480802,\n",
    "    (3, 4): 0.614810743,\n",
    "    (3, 5): 0.2362195029,\n",
    "    (3, 6): 0.5512205929,\n",
    "    (3, 7): 0.6291890911,\n",
    "    (4, 0): 0.3702657392,\n",
    "    (4, 3): 0.6957271861,\n",
    "    (4, 7): 0.4405787781,\n",
    "    (4, 11): 0.2703157886,\n",
    "    (5, 3): 0.3070761406,\n",
    "    (5, 7): 0.4992432842,\n",
    "    (5, 8): 0.5476203713,\n",
    "    (6, 3): 0.3080401627,\n",
    "    (6, 20): 0.4464421034,\n",
    "    (7, 3): 0.2765954887,\n",
    "    (7, 4): 0.3008769896,\n",
    "    (7, 5): 0.4248384488,\n",
    "    (7, 16): 0.446087055,\n",
    "    (7, 21): 0.06400726476,\n",
    "    (8, 5): 0.3904881582,\n",
    "    (8, 9): 0.4511434057,\n",
    "    (8, 17): 0.2794885521,\n",
    "    (9, 8): 0.5676669918,\n",
    "    (9, 10): 0.369577537,\n",
    "    (9, 12): 0.4926916878,\n",
    "    (10, 9): 0.3388785174,\n",
    "    (10, 13): 0.3369130153,\n",
    "    (10, 17): 0.6073079151,\n",
    "    (11, 4): 0.2826981204,\n",
    "    (11, 14): 0.3836916617,\n",
    "    (11, 15): 0.5666477776,\n",
    "    (11, 18): 0.3129632055,\n",
    "    (12, 9): 0.6974369733,\n",
    "    (12, 14): 0.34985332,\n",
    "    (12, 17): 0.5475669363,\n",
    "    (12, 19): 0.4435253526,\n",
    "    (12, 26): 0.5353101287,\n",
    "    (13, 2): 0.282631413,\n",
    "    (13, 10): 0.2330662032,\n",
    "    (13, 23): 0.2977541939,\n",
    "    (14, 11): 0.3228937374,\n",
    "    (14, 12): 0.5478816812,\n",
    "    (15, 0): 0.6488606563,\n",
    "    (15, 2): 0.4067398184,\n",
    "    (15, 11): 0.2424653154,\n",
    "    (16, 7): 0.4805317103,\n",
    "    (16, 18): 0.3368952343,\n",
    "    (17, 8): 0.5499445657,\n",
    "    (17, 10): 0.4651820486,\n",
    "    (17, 12): 0.4265108166,\n",
    "    (18, 11): 0.272377799,\n",
    "    (18, 16): 0.5449429935,\n",
    "    (18, 19): 0.4142552459,\n",
    "    (18, 21): 0.5832687723,\n",
    "    (18, 25): 0.5626267756,\n",
    "    (19, 12): 0.3915065111,\n",
    "    (19, 18): 0.4083492938,\n",
    "    (19, 20): 0.491577807,\n",
    "    (19, 22): 0.5009950314,\n",
    "    (19, 24): 0.479048743,\n",
    "    (20, 6): 0.3185120973,\n",
    "    (20, 19): 0.5759215123,\n",
    "    (20, 21): 0.4621806759,\n",
    "    (20, 24): 0.4346068608,\n",
    "    (20, 26): 0.5205927609,\n",
    "    (21, 7): 0.1381360828,\n",
    "    (21, 18): 0.2236546413,\n",
    "    (21, 20): 0.4344021531,\n",
    "    (22, 19): 0.4416796452,\n",
    "    (23, 2): 0.5061978469,\n",
    "    (23, 13): 0.7899769485,\n",
    "    (23, 26): 0.2907848836,\n",
    "    (24, 19): 0.1546036158,\n",
    "    (24, 20): 0.2895175086,\n",
    "    (25, 18): 0.1411063944,\n",
    "    (26, 12): 0.5991747676,\n",
    "    (26, 20): 0.2902872652,\n",
    "    (26, 23): 0.198884108\n",
    "}\n",
    "# Function to calculate the reward for a given state and action\n",
    "def calculate_reward(state, action):\n",
    "    if (state, action) in information:\n",
    "        return information[(state, action)]\n",
    "    else:\n",
    "        return 0  # Default reward for invalid action\n",
    "\n",
    "# Convert adjacency list to matrix\n",
    "def adjacency_list_to_matrix(adj_list):\n",
    "    num_nodes = len(adj_list)\n",
    "    matrix = np.zeros((num_nodes, num_nodes))\n",
    "    for node, neighbors in adj_list.items():\n",
    "        for neighbor in neighbors:\n",
    "            matrix[node, neighbor] = 1\n",
    "    return matrix\n",
    "\n",
    "# Convert information dictionary to matrix\n",
    "def information_to_matrix(information, num_nodes):\n",
    "    R = np.zeros((num_nodes, num_nodes))\n",
    "    for (from_node, to_node), reward in information.items():\n",
    "        R[from_node, to_node] = reward\n",
    "    return R\n",
    "\n",
    "# Q-learning parameters\n",
    "gamma = 0.9  # Discount factor\n",
    "num_episodes = 10\n",
    "\n",
    "# Convert adjacency list to matrix\n",
    "num_nodes = len(adj_list)\n",
    "adj_matrix = adjacency_list_to_matrix(adj_list)\n",
    "\n",
    "# Convert information dictionary to matrix\n",
    "R = information_to_matrix(information, num_nodes)\n",
    "\n",
    "# Initialize Q-matrix\n",
    "Q = np.zeros_like(R)\n",
    "\n",
    "# Q-learning algorithm\n",
    "def q_learning(R, Q, num_episodes):\n",
    "    for _ in range(num_episodes):\n",
    "        state = np.random.randint(num_nodes)  # Random initial state\n",
    "        while True:\n",
    "            possible_actions = np.where(adj_matrix[state] == 1)[0]  # Get possible actions\n",
    "            action = np.random.choice(possible_actions)  # Choose action randomly\n",
    "            next_state = action  # Transition to next state\n",
    "            max_next_Q = np.max(Q[next_state])  # Find maximum Q-value for next state\n",
    "            Q[state, action] = R[state, action] + gamma * max_next_Q  # Update Q-value\n",
    "            state = next_state  # Update state\n",
    "            if state == state:  # Check if episode terminates\n",
    "                break\n",
    "\n",
    "\n",
    "# Function to find the shortest path using learned Q-values\n",
    "def q_learning_shortest_path(Q, start, goal):\n",
    "    path = [start]\n",
    "    while start != goal:\n",
    "        next_step = np.argmax(Q[start])\n",
    "        yield next_step\n",
    "        start = next_step\n",
    "\n",
    "# Example usage\n",
    "shortest_path_generator = q_learning_shortest_path(Q, 0, 26)\n",
    "shortest_path = list(shortest_path_generator)\n",
    "print(\"Shortest path:\", shortest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674425d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
